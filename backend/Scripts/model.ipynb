{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcatboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CatBoostClassifier\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report\n",
      "File \u001b[1;32mc:\\Users\\Nawfel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\catboost\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     FeaturesData, EFstrType, EShapCalcType, EFeaturesSelectionAlgorithm, EFeaturesSelectionGrouping,\n\u001b[0;32m      3\u001b[0m     Pool, CatBoost, CatBoostClassifier, CatBoostRegressor, CatBoostRanker, CatBoostError, cv, sample_gaussian_process, train,\n\u001b[0;32m      4\u001b[0m     sum_models, _have_equal_features, to_regressor, to_classifier, to_ranker, MultiRegressionCustomMetric,\n\u001b[0;32m      5\u001b[0m     MultiRegressionCustomObjective, MultiTargetCustomMetric, MultiTargetCustomObjective\n\u001b[0;32m      6\u001b[0m )  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VERSION \u001b[38;5;28;01mas\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeaturesData\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEFstrType\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEShapCalcType\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEFeaturesSelectionAlgorithm\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEFeaturesSelectionGrouping\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPool\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCatBoost\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCatBoostClassifier\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCatBoostRegressor\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCatBoostRanker\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCatboostError\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultiTargetCustomMetric\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultiTargetCustomObjective\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     14\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\Nawfel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\catboost\\core.py:45\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplot_helpers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save_plot_file, try_plot_offline, OfflineMetricVisualizer\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _catboost\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BuiltinMetric\n",
      "File \u001b[1;32mc:\\Users\\Nawfel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\catboost\\plot_helpers.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _catboost\n\u001b[0;32m      6\u001b[0m fspath \u001b[38;5;241m=\u001b[39m _catboost\u001b[38;5;241m.\u001b[39mfspath\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtry_plot_offline\u001b[39m(figs):\n",
      "File \u001b[1;32m_catboost.pyx:1\u001b[0m, in \u001b[0;36minit _catboost\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "#Document qui vise à explorer le dataset de la base de données de KBO\n",
    "\n",
    "#Importation des librairies\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin relatif vers le dossier de données\n",
    "data_dir = os.path.join('..', '..', 'data')\n",
    "\n",
    "# Chemins complets vers chaque fichier CSV\n",
    "activity_path = os.path.join(data_dir, 'activity.csv')\n",
    "address_path = os.path.join(data_dir, 'address.csv')\n",
    "branch_path = os.path.join(data_dir, 'branch.csv')\n",
    "code_path = os.path.join(data_dir, 'code.csv')\n",
    "contact_path = os.path.join(data_dir, 'contact.csv')\n",
    "denomination_path = os.path.join(data_dir, 'denomination.csv')\n",
    "enterprise_path = os.path.join(data_dir, 'enterprise.csv')\n",
    "establishment_path = os.path.join(data_dir, 'establishment.csv')\n",
    "meta_path = os.path.join(data_dir, 'meta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les datasets avec Dask sans spécifier de types de données\n",
    "activity_df = pd.read_csv(activity_path)\n",
    "address_df = pd.read_csv(address_path)\n",
    "branch_df = pd.read_csv(branch_path)\n",
    "code_df = pd.read_csv(code_path)\n",
    "contact_df = pd.read_csv(contact_path)\n",
    "denomination_df = pd.read_csv(denomination_path)\n",
    "enterprise_df = pd.read_csv(enterprise_path)\n",
    "establishment_df = pd.read_csv(establishment_path)\n",
    "meta_df = pd.read_csv(meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(activity_df.columns)\n",
    "print(address_df.columns)\n",
    "print(branch_df.columns)\n",
    "print(code_df.columns)\n",
    "print(contact_df.columns)\n",
    "print(denomination_df.columns)\n",
    "print(enterprise_df.columns)\n",
    "print(establishment_df.columns)\n",
    "print(meta_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir les colonnes avec des types mixtes\n",
    "activity_df['EntityNumber'] = activity_df['EntityNumber'].astype(str)\n",
    "activity_df['Classification'] = activity_df['Classification'].astype(str)\n",
    "address_df['EntityNumber'] = address_df['EntityNumber'].astype(str)\n",
    "address_df['Zipcode'] = pd.to_numeric(address_df['Zipcode'], errors='coerce')\n",
    "address_df['HouseNumber'] = address_df['HouseNumber'].astype(str)\n",
    "address_df['DateStrikingOff'] = pd.to_datetime(address_df['DateStrikingOff'], errors='coerce')\n",
    "branch_df['Id'] = branch_df['Id'].astype(str)\n",
    "branch_df['StartDate'] = pd.to_datetime(branch_df['StartDate'], errors='coerce')\n",
    "branch_df['EnterpriseNumber'] = branch_df['EnterpriseNumber'].astype(str)\n",
    "code_df['Category'] = code_df['Category'].astype(str)\n",
    "code_df['Code'] = code_df['Code'].astype(str)\n",
    "code_df['Language'] = code_df['Language'].astype(str)\n",
    "code_df['Description'] = code_df['Description'].astype(str)\n",
    "contact_df['EntityNumber'] = contact_df['EntityNumber'].astype(str)\n",
    "contact_df['EntityContact'] = contact_df['EntityContact'].astype(str)\n",
    "contact_df['ContactType'] = contact_df['ContactType'].astype(str)\n",
    "contact_df['Value'] = contact_df['Value'].astype(str)\n",
    "denomination_df['EntityNumber'] = denomination_df['EntityNumber'].astype(str)\n",
    "denomination_df['Denomination'] = denomination_df['Denomination'].astype(str)\n",
    "enterprise_df['EnterpriseNumber'] = enterprise_df['EnterpriseNumber'].astype(str)\n",
    "enterprise_df['JuridicalForm'] = pd.to_numeric(enterprise_df['JuridicalForm'], errors='coerce')\n",
    "enterprise_df['JuridicalFormCAC'] = pd.to_numeric(enterprise_df['JuridicalFormCAC'], errors='coerce')\n",
    "enterprise_df['StartDate'] = pd.to_datetime(enterprise_df['StartDate'], errors='coerce')\n",
    "establishment_df['EstablishmentNumber'] = establishment_df['EstablishmentNumber'].astype(str)\n",
    "establishment_df['StartDate'] = pd.to_datetime(establishment_df['StartDate'], errors='coerce')\n",
    "establishment_df['EnterpriseNumber'] = establishment_df['EnterpriseNumber'].astype(str)\n",
    "meta_df['Variable'] = meta_df['Variable'].astype(str)\n",
    "meta_df['Value'] = meta_df['Value'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Échantillonner les données (par exemple, 10% des données)\n",
    "sample_fraction = 0.1\n",
    "\n",
    "activity_df = activity_df.sample(frac=sample_fraction, random_state=42)\n",
    "address_df = address_df.sample(frac=sample_fraction, random_state=42)\n",
    "branch_df = branch_df.sample(frac=sample_fraction, random_state=42)\n",
    "code_df = code_df.sample(frac=sample_fraction, random_state=42)\n",
    "contact_df = contact_df.sample(frac=sample_fraction, random_state=42)\n",
    "denomination_df = denomination_df.sample(frac=sample_fraction, random_state=42)\n",
    "enterprise_df = enterprise_df.sample(frac=sample_fraction, random_state=42)\n",
    "establishment_df = establishment_df.sample(frac=sample_fraction, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusionner les datasets en utilisant EntityNumber comme clé primaire\n",
    "merged_df = activity_df.merge(enterprise_df, left_on='EntityNumber', right_on='EnterpriseNumber', how='left')\n",
    "merged_df = merged_df.merge(address_df, on='EntityNumber', how='left')\n",
    "merged_df = merged_df.merge(branch_df, left_on='EntityNumber', right_on='EnterpriseNumber', how='left')\n",
    "merged_df = merged_df.merge(contact_df, on='EntityNumber', how='left')\n",
    "merged_df = merged_df.merge(denomination_df, on='EntityNumber', how='left')\n",
    "merged_df = merged_df.merge(establishment_df, left_on='EntityNumber', right_on='EnterpriseNumber', how='left')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les colonnes constantes\n",
    "merged_df = merged_df.drop(columns=[\n",
    "    'Status', 'EnterpriseNumber_x', 'EnterpriseNumber_y', 'Id', 'EntityContact', 'ContactType',\n",
    "    'Language', 'TypeOfDenomination', 'Denomination', 'EstablishmentNumber', 'EnterpriseNumber'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplacer les valeurs manquantes pour les colonnes numériques et non numériques\n",
    "def fill_missing_values(df):\n",
    "    for col in df.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            df[col] = df[col].fillna(df[col].mean())\n",
    "        else:\n",
    "            df[col] = df[col].fillna(df[col].mode().iloc[0])\n",
    "    return df\n",
    "\n",
    "# Appliquer la fonction pour remplacer les valeurs manquantes\n",
    "merged_df = fill_missing_values(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodage des colonnes catégorielles restantes\n",
    "categorical_columns = ['TypeOfAddress', 'CountryNL', 'CountryFR', 'MunicipalityNL', 'MunicipalityFR',\n",
    "                       'StreetNL', 'StreetFR', 'Box', 'ExtraAddressInfo']\n",
    "\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    merged_df[col] = le.fit_transform(merged_df[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retirer les colonnes datetime\n",
    "datetime_cols = merged_df.select_dtypes(include=['datetime']).columns\n",
    "merged_df = merged_df.drop(columns=datetime_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparer les caractéristiques et la cible\n",
    "features = merged_df.drop(columns=['Classification'])\n",
    "target = merged_df['Classification'].map(lambda x: 1 if x == 'MAIN' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Échantillonner les données (par exemple, 10% des données)\n",
    "sample_fraction = 0.1\n",
    "X_sampled, _, y_sampled, _ = train_test_split(features, target, test_size=1 - sample_fraction, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diviser les données échantillonnées en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sampled, y_sampled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner un modèle de classification (CatBoost)\n",
    "model = CatBoostClassifier(verbose=0)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédire sur l'ensemble de test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Évaluer le modèle\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Évaluer l'importance des caractéristiques\n",
    "importances = model.feature_importances_\n",
    "feature_names = features.columns\n",
    "feature_importances = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "feature_importances = feature_importances.sort_values('importance', ascending=False)\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model, 'model.pkl')  # Sauvegarder le modèle"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
